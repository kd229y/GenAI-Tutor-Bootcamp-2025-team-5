{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be68iGaxWJ3V"
      },
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Y3OiA2vTkZ-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "from typing import List\n",
        "\n",
        "import chromadb\n",
        "from chromadb.api.types import Documents, Embeddings\n",
        "from chromadb.utils.embedding_functions import EmbeddingFunction\n",
        "\n",
        "import google.generativeai as genai\n",
        "\n",
        "import gradio as gr\n",
        "import fitz  # 要安裝PyMuPDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATPAganzwKjS"
      },
      "source": [
        "# Download PDF and Extract text from PDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnd8o8dJWwfh"
      },
      "outputs": [],
      "source": [
        "def download_pdf(url, save_path):\n",
        "    \"\"\"\n",
        "    從指定 URL 下載 PDF 文件並儲存到本地。\n",
        "\n",
        "    :param url: PDF 文件的網址 (string)\n",
        "    :param save_path: PDF 文件儲存的本地路徑 (string)\n",
        "    \"\"\"\n",
        "    # 使用 requests 模組發送 HTTP GET 請求以獲取 PDF 文件\n",
        "    response = requests.get(url)\n",
        "\n",
        "    # 打開指定的本地儲存路徑，使用二進位寫入模式 ('wb')\n",
        "    with open(save_path, 'wb') as f:\n",
        "        # 將下載的文件內容寫入到本地文件中\n",
        "        f.write(response.content)\n",
        "\n",
        "\n",
        "def extract_text_from_pdf_file_obj(file):\n",
        "    \"\"\"\n",
        "    從 PDF 檔案物件提取文本內容。\n",
        "\n",
        "    :param file: PDF 文件的檔案物件 (e.g., 通過 open(file, 'rb') 獲取)\n",
        "    :return: 提取的文本內容 (string)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with fitz.open(file.name) as doc:\n",
        "            pdf_text = \"\"\n",
        "            for page in doc:\n",
        "                pdf_text += page.get_text()\n",
        "        return pdf_text\n",
        "    except Exception as e:\n",
        "        return f\"Error while reading PDF: {str(e)}\"\n",
        "\n",
        "\n",
        "def extract_text_from_pdf_file_path(file_path):\n",
        "    \"\"\"\n",
        "    從 PDF 文件的路徑提取文本內容。\n",
        "\n",
        "    :param file_path: PDF 文件的檔案路徑 (string)\n",
        "    :return: 提取的文本內容 (string)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with fitz.open(file_path) as doc:\n",
        "            pdf_text = \"\"\n",
        "            for page in doc:\n",
        "                pdf_text += page.get_text()\n",
        "        return pdf_text\n",
        "    except Exception as e:\n",
        "        return f\"Error while reading PDF: {str(e)}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DF0z6jspWTyF"
      },
      "source": [
        "# ToDo:\n",
        "- Text splitting\n",
        "- ChromaDB\n",
        "- Prompt Construction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5bU0WilGZca"
      },
      "source": [
        "## Implement text splitting function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GrW4ejl4Fm5u"
      },
      "outputs": [],
      "source": [
        "# 分割文本為小塊\n",
        "def split_text(text: str, max_chunk_size: int = 500, overlap: int = 50) -> List[str]:\n",
        "    \"\"\"\n",
        "    將長文本分割為多個小塊，支援塊之間的重疊。\n",
        "\n",
        "    :param text: 要分割的文本 (string)\n",
        "    :param max_chunk_size: 每個文本塊的最大大小 (int)\n",
        "    :param overlap: 每個文本塊之間的重疊大小 (int)\n",
        "    :return: 分割後的文本塊列表 (List of strings)\n",
        "    \"\"\"\n",
        "    chunks = []\n",
        "    start = 0\n",
        "    while start < len(text):\n",
        "        end = min(start + max_chunk_size, len(text))\n",
        "        chunks.append(text[start:end].strip())\n",
        "        start += max_chunk_size - overlap\n",
        "    return chunks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pxb_4mmFGg-h"
      },
      "source": [
        "## Custom embedding function using Gemini API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qZqtNV_nFy-M"
      },
      "outputs": [],
      "source": [
        "# 自定義 Gemini 嵌入函數\n",
        "class GeminiEmbeddingFunction(EmbeddingFunction):\n",
        "    def __init__(self, api_key: str, model: str = \"models/embedding-001\", title: str = \"Custom query\"):\n",
        "        self.api_key = api_key\n",
        "        self.model = model\n",
        "        self.title = title\n",
        "        genai.configure(api_key=self.api_key)\n",
        "\n",
        "    def __call__(self, input: Documents) -> Embeddings:\n",
        "        return [\n",
        "            genai.embed_content(\n",
        "                model=self.model,\n",
        "                content=doc,\n",
        "                task_type=\"retrieval_document\",\n",
        "                title=self.title\n",
        "            )[\"embedding\"]\n",
        "            for doc in input\n",
        "        ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qi9IA2FiGmwk"
      },
      "source": [
        "## Implement ChromaDB creation and querying"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "75pEi_qbWwfj"
      },
      "outputs": [],
      "source": [
        "# 向現有的 ChromaDB 集合中新增文件。\n",
        "def update_chroma_db(client, collection_name: str, new_documents: List[str]):\n",
        "    \"\"\"\n",
        "    向現有的 ChromaDB 集合中新增文件。\n",
        "\n",
        "    :param path: ChromaDB 的資料庫路徑 (string)\n",
        "    :param collection_name: 要更新的集合名稱 (string)\n",
        "    :param new_documents: 要新增的文件列表 (List of strings)\n",
        "    \"\"\"\n",
        "\n",
        "    # Get the existing collection by name\n",
        "    collection = client.get_or_create_collection(collection_name)\n",
        "\n",
        "    # Add new documents to the collection\n",
        "    for i, document in enumerate(new_documents):\n",
        "        collection.add(\n",
        "            ids=[f\"new_doc_{i}\"],  # New unique ID for each document\n",
        "            documents=[document],  # New document content\n",
        "        )\n",
        "\n",
        "    print(f\"Added {len(new_documents)} new documents to the collection '{collection_name}'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bqBRdBb10CB6"
      },
      "outputs": [],
      "source": [
        "# 查詢相關段落\n",
        "def get_relevant_passage(query: str, db, name: str, n_results: int = 3) -> List[str]:\n",
        "    \"\"\"\n",
        "    從指定的 ChromaDB 集合中查詢與給定問題相關的段落。\n",
        "\n",
        "    :param query: 用戶的查詢語句 (string)\n",
        "    :param db: 連接的 ChromaDB 資料庫對象\n",
        "    :param name: 要查詢的集合名稱 (string)\n",
        "    :param n_results: 返回的相關結果數量 (int, 默認為 3)\n",
        "    :ret\n",
        "    \"\"\"\n",
        "    collection = db.get_collection(name)\n",
        "    results = collection.query(query_texts=[query], n_results=n_results)\n",
        "    return results[\"documents\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6Mb0RSDGwRf"
      },
      "outputs": [],
      "source": [
        "# 建構提示詞\n",
        "def make_rag_prompt(query: str, relevant_passages: List[str]) -> str:\n",
        "    context = \"\\n\\n\".join(relevant_passages)\n",
        "    return f\"\"\"\n",
        "    You are an intelligent assistant. Use the following context to answer the question:\n",
        "\n",
        "    Context:\n",
        "    {context}\n",
        "\n",
        "    Question:\n",
        "    {query}\n",
        "\n",
        "    Provide a concise and accurate response.\n",
        "    \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSO0EfflwBUa"
      },
      "source": [
        "# LLM Response Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0T1PfvaWwfk",
        "outputId": "66a01aa4-e3a5-40a0-a76f-17f8e30669f5"
      },
      "outputs": [],
      "source": [
        "# Check Gemini API key\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "# 載入 .env 文件中的所有變數\n",
        "load_dotenv(\"key.env\")\n",
        "\n",
        "# 使用 os.getenv 獲取環境變數\n",
        "api_key = os.getenv('Geminiapikey')\n",
        "\n",
        "\n",
        "# 確認變數是否正確載入\n",
        "print(f\"Gemini api key: {api_key}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "toYV28pPv_hj"
      },
      "outputs": [],
      "source": [
        "# Generate answer using Gemini Pro API\n",
        "def generate_answer(prompt: str):\n",
        "    load_dotenv()\n",
        "    api_key = os.getenv('Geminiapikey')\n",
        "    gemini_api_key = api_key\n",
        "    if not gemini_api_key:\n",
        "        raise ValueError(\n",
        "            \"Gemini API Key not provided. Please provide GEMINI_API_KEY as an environment variable\")\n",
        "    genai.configure(api_key=gemini_api_key)\n",
        "    model = genai.GenerativeModel('gemini-pro')\n",
        "    result = model.generate_content(prompt)\n",
        "    return result.text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nDaJf9YWwfl"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fyH03P_Wwfl",
        "outputId": "6f1d9da0-715c-4797-cf9b-db06c5aca7ea"
      },
      "outputs": [],
      "source": [
        "# Set up configurations\n",
        "pdf_url = \"https://services.google.com/fh/files/misc/ai_adoption_framework_whitepaper.pdf\"\n",
        "pdf_path = \"ai_adoption_framework_whitepaper.pdf\"\n",
        "\n",
        "db_folder = \"chroma_db\"\n",
        "db_path = os.path.join(os.getcwd(), db_folder)\n",
        "\n",
        "# Create database directory\n",
        "if not os.path.exists(db_folder):\n",
        "    os.makedirs(db_folder)\n",
        "\n",
        "\n",
        "client = chromadb.PersistentClient(path=db_path)\n",
        "\n",
        "# a database unit in Chroma is called collection, so db here means collection\n",
        "db_name = \"rag_experiment\"\n",
        "client.get_or_create_collection(db_name)\n",
        "print(f\"{db_name} is created\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5xwd91VWwfl",
        "outputId": "4fc5eb44-5ba9-418e-a660-00cd8e9d6b5b"
      },
      "outputs": [],
      "source": [
        "# Download and process PDF\n",
        "download_pdf(pdf_url, pdf_path)\n",
        "pdf_text = extract_text_from_pdf_file_path(pdf_path)\n",
        "\n",
        "# Split text into chunks\n",
        "chunked_text = split_text(pdf_text)\n",
        "\n",
        "update_chroma_db(client, db_name, chunked_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "lI6r-xXzWwfl",
        "outputId": "61f55090-60f8-4504-fad5-de8b2ddde2ed"
      },
      "outputs": [],
      "source": [
        "# Process user query\n",
        "query = 'what is this file talking about?'\n",
        "relevant_text = get_relevant_passage(query, client, db_name, n_results=3)\n",
        "\n",
        "# Generate and display answer\n",
        "if relevant_text:\n",
        "    final_prompt = make_rag_prompt(query, \"\".join(relevant_text))\n",
        "    answer = generate_answer(final_prompt)\n",
        "    print(\"\\nGenerated Answer:\", answer)\n",
        "else:\n",
        "    print(\"No relevant information found for the given query.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uahs6MZoWwfl"
      },
      "source": [
        "# Combine Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3COvG9ayWwfl"
      },
      "outputs": [],
      "source": [
        "# 從 PDF 文件提取文本，分割文本為小塊，並更新 ChromaDB 集合。\n",
        "def add_document_to_db(client, db_name, file):\n",
        "    \"\"\"\n",
        "    :param db_path: ChromaDB 資料庫的路徑 (string)\n",
        "    :param db_name: 要更新的 ChromaDB 集合名稱 (string)\n",
        "    :param file: PDF 文件的二進位文件對象 (BinaryIO)\n",
        "    \"\"\"\n",
        "    pdf_text = extract_text_from_pdf_file_obj(file)\n",
        "\n",
        "    # Split text into chunks\n",
        "    chunked_text = split_text(pdf_text)\n",
        "\n",
        "    update_chroma_db(client, db_name, chunked_text)\n",
        "\n",
        "    print(f\"{db_name} is updated\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qpF17N1HWwfm"
      },
      "outputs": [],
      "source": [
        "# 基於 RAG (Retrieval-Augmented Generation) 流程生成回答。\n",
        "def rag_response(query, client, db_name):\n",
        "    \"\"\"\n",
        "    :param query: 用戶的查詢語句 (string)\n",
        "    :param client: 連接的 ChromaDB 資料庫客戶端\n",
        "    :param db_name: 查詢的集合名稱 (string)\n",
        "    :return: 生成的回答或錯誤信息 (string)\n",
        "    \"\"\"\n",
        "    # Process user query\n",
        "    relevant_text = get_relevant_passage(query, client, db_name, n_results=3)\n",
        "\n",
        "    # Generate and display answer\n",
        "    if relevant_text:\n",
        "        final_prompt = make_rag_prompt(query, \"\".join(relevant_text))\n",
        "        answer = generate_answer(final_prompt)\n",
        "        response = \"\\nGenerated Answer:\"+answer\n",
        "    else:\n",
        "        response = \"No relevant information found for the given query.\"\n",
        "\n",
        "    return response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LyBBDZfwlzl"
      },
      "source": [
        "# Main execution\n",
        "## ToDo:\n",
        " - Chat history\n",
        " - Multiple file injest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JirE2HszWwfm"
      },
      "source": [
        "# Initilaize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KhQLbvm4Wwfm"
      },
      "outputs": [],
      "source": [
        "# 初始化 ChromaDB 資料庫，創建資料庫目錄並設置集合。\n",
        "def initialize_database(db_folder: str, db_name: str) -> chromadb.PersistentClient:\n",
        "    \"\"\"\n",
        "    :param db_folder: 資料庫文件夾名稱 (string)\n",
        "    :param db_name: 資料庫集合名稱 (string)\n",
        "    :return: 已初始化的 ChromaDB 客戶端 (chromadb.PersistentClient)\n",
        "    \"\"\"\n",
        "    # 獲取當前工作目錄，構建完整的資料庫路徑\n",
        "    db_path = os.path.join(os.getcwd(), db_folder)\n",
        "\n",
        "    # 如果資料庫目錄不存在，則創建該目錄\n",
        "    if not os.path.exists(db_folder):\n",
        "        os.makedirs(db_folder)\n",
        "\n",
        "    # 創建一個 PersistentClient 連接到指定的資料庫路徑\n",
        "    client = chromadb.PersistentClient(path=db_path)\n",
        "\n",
        "    # 在資料庫中創建或獲取指定名稱的集合\n",
        "    client.get_or_create_collection(db_name)\n",
        "\n",
        "    # 打印提示信息，確認集合已創建或存在\n",
        "    print(f\"Collection '{db_name}' is initialized in {db_folder}.\")\n",
        "\n",
        "    # 返回已初始化的客戶端對象\n",
        "    return client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61PrhwWAWwfm",
        "outputId": "0e475c58-8bce-4a32-ee61-e30b11b9b07b"
      },
      "outputs": [],
      "source": [
        "db_folder = \"chroma_db\"\n",
        "db_name = \"rag_experiment\"\n",
        "\n",
        "client = initialize_database(db_folder, db_name)\n",
        "print(client)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hge6K8BxWwfm"
      },
      "source": [
        "# gradio UI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnyvCnc5Wwfn",
        "outputId": "9c426c4a-6edd-4c96-f13a-af6a8cba7e4b"
      },
      "outputs": [],
      "source": [
        "from flask import Flask, request, jsonify\n",
        "from flask_cors import CORS\n",
        "app = Flask(__name__)\n",
        "#允許跨域請求\n",
        "CORS(app)\n",
        "# 初始化聊天歷史\n",
        "chat_history = []  # 用於存儲用戶和機器人之間的所有對話\n",
        "\n",
        "# 定義用戶輸入的交互邏輯\n",
        "def respond(input_text, history):\n",
        "    \"\"\"\n",
        "    處理用戶輸入，生成回應並更新聊天歷史。\n",
        "    Args:\n",
        "        input_text (str): 用戶的輸入訊息。\n",
        "        history (list): 聊天歷史記錄。\n",
        "    Returns:\n",
        "        tuple: 清空的輸入框和更新後的聊天歷史。\n",
        "    \"\"\"\n",
        "    # 確保聊天歷史初始化為空列表\n",
        "    if history is None:\n",
        "        history = []\n",
        "\n",
        "    # 使用 RAG 模型生成回應\n",
        "    bot_response = rag_response(input_text, client, db_name)\n",
        "\n",
        "    # 將用戶輸入和機器人回應追加到歷史記錄\n",
        "    history.append([input_text, bot_response])  # 每次對話為 [用戶訊息, 機器人回應]\n",
        "\n",
        "    return \"\", history  # 返回清空的輸入框和新的聊天歷史\n",
        "\n",
        "# 處理 PDF 文件上傳的函數\n",
        "\n",
        "\n",
        "def handle_pdf_upload(file):\n",
        "    \"\"\"\n",
        "    處理用戶上傳的 PDF 文件。\n",
        "    Args:\n",
        "        file (File): 上傳的文件對象。\n",
        "    Returns:\n",
        "        str: 文件處理狀態信息。\n",
        "    \"\"\"\n",
        "    if file is None:\n",
        "        return \"尚未上傳文件。\"\n",
        "\n",
        "    # 檢查文件格式是否為 PDF\n",
        "    if not file.name.endswith(\".pdf\"):\n",
        "        return \"僅支持上傳 PDF 文件！\"\n",
        "\n",
        "    # 模擬將文件添加到數據庫\n",
        "    add_document_to_db(client, db_name, file)\n",
        "    return f\"已上傳文件：{file.name}\"\n",
        "\n",
        "@app.route('/respond', methods=['POST'])\n",
        "def respond_api():\n",
        "    data = request.json\n",
        "    message = data.get('user_message')\n",
        "    # 初始化 history 為空列表\n",
        "    history = []\n",
        "\n",
        "    # 呼叫 respond 函數，並將 message 和 history 作為參數\n",
        "    _, updated_history = respond(message, history)\n",
        "    bot_response = updated_history[-1][1] if updated_history else \"無回應\"\n",
        "\n",
        "    return jsonify({\"bot_message\": bot_response})\n",
        "\n",
        "@app.route('/upload', methods=['POST'])\n",
        "def upload_file():\n",
        "    file = request.files['file']\n",
        "    response = handle_pdf_upload(file)\n",
        "    return jsonify(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "iSBU0bkuWwfn",
        "outputId": "7e62e857-8bc1-4a72-dc98-39dac13ac437"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on all addresses (0.0.0.0)\n",
            " * Running on http://127.0.0.1:5000\n",
            " * Running on http://172.24.209.41:5000\n",
            "\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "127.0.0.1 - - [19/Feb/2025 20:39:41] \"POST /upload HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [19/Feb/2025 20:39:53] \"OPTIONS /respond HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [19/Feb/2025 20:39:56] \"POST /respond HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [19/Feb/2025 20:40:15] \"OPTIONS /respond HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [19/Feb/2025 20:40:17] \"POST /respond HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [19/Feb/2025 20:40:25] \"OPTIONS /respond HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [19/Feb/2025 20:40:28] \"POST /respond HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [19/Feb/2025 20:41:18] \"OPTIONS /respond HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [19/Feb/2025 20:41:21] \"POST /respond HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [19/Feb/2025 20:41:39] \"OPTIONS /respond HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [19/Feb/2025 20:41:42] \"POST /respond HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [19/Feb/2025 20:41:53] \"OPTIONS /respond HTTP/1.1\" 200 -\n",
            "[2025-02-19 20:41:55,936] ERROR in app: Exception on /respond [POST]\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/kd/.local/lib/python3.10/site-packages/flask/app.py\", line 1473, in wsgi_app\n",
            "    response = self.full_dispatch_request()\n",
            "  File \"/home/kd/.local/lib/python3.10/site-packages/flask/app.py\", line 882, in full_dispatch_request\n",
            "    rv = self.handle_user_exception(e)\n",
            "  File \"/home/kd/.local/lib/python3.10/site-packages/flask_cors/extension.py\", line 194, in wrapped_function\n",
            "    return cors_after_request(app.make_response(f(*args, **kwargs)))\n",
            "  File \"/home/kd/.local/lib/python3.10/site-packages/flask/app.py\", line 880, in full_dispatch_request\n",
            "    rv = self.dispatch_request()\n",
            "  File \"/home/kd/.local/lib/python3.10/site-packages/flask/app.py\", line 865, in dispatch_request\n",
            "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n",
            "  File \"/tmp/ipykernel_28674/780835804.py\", line 61, in respond_api\n",
            "    _, updated_history = respond(message, history)\n",
            "  File \"/tmp/ipykernel_28674/780835804.py\", line 24, in respond\n",
            "    bot_response = rag_response(input_text, client, db_name)\n",
            "  File \"/tmp/ipykernel_28674/3723904141.py\", line 15, in rag_response\n",
            "    answer = generate_answer(final_prompt)\n",
            "  File \"/tmp/ipykernel_28674/2126507025.py\", line 12, in generate_answer\n",
            "    return result.text\n",
            "  File \"/home/kd/.local/lib/python3.10/site-packages/google/generativeai/types/generation_types.py\", line 483, in text\n",
            "    raise ValueError(\n",
            "ValueError: (\"Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 3. The candidate's safety_ratings are: [category: HARM_CATEGORY_SEXUALLY_EXPLICIT\\nprobability: NEGLIGIBLE\\n, category: HARM_CATEGORY_HATE_SPEECH\\nprobability: LOW\\n, category: HARM_CATEGORY_HARASSMENT\\nprobability: MEDIUM\\n, category: HARM_CATEGORY_DANGEROUS_CONTENT\\nprobability: NEGLIGIBLE\\n].\", [category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
            "probability: NEGLIGIBLE\n",
            ", category: HARM_CATEGORY_HATE_SPEECH\n",
            "probability: LOW\n",
            ", category: HARM_CATEGORY_HARASSMENT\n",
            "probability: MEDIUM\n",
            ", category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
            "probability: NEGLIGIBLE\n",
            "])\n",
            "127.0.0.1 - - [19/Feb/2025 20:41:56] \"\u001b[35m\u001b[1mPOST /respond HTTP/1.1\u001b[0m\" 500 -\n",
            "127.0.0.1 - - [19/Feb/2025 20:42:48] \"OPTIONS /respond HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [19/Feb/2025 20:42:50] \"POST /respond HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [19/Feb/2025 20:44:10] \"OPTIONS /respond HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [19/Feb/2025 20:44:14] \"POST /respond HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [19/Feb/2025 20:47:05] \"OPTIONS /respond HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [19/Feb/2025 20:47:07] \"POST /respond HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [19/Feb/2025 20:50:52] \"OPTIONS /respond HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [19/Feb/2025 20:50:57] \"POST /respond HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [19/Feb/2025 20:51:23] \"POST /upload HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [19/Feb/2025 20:51:28] \"OPTIONS /respond HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [19/Feb/2025 20:51:31] \"POST /respond HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [19/Feb/2025 20:52:04] \"OPTIONS /respond HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [19/Feb/2025 20:52:07] \"POST /respond HTTP/1.1\" 200 -\n"
          ]
        }
      ],
      "source": [
        "app.run(host=\"0.0.0.0\", port=5000)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
