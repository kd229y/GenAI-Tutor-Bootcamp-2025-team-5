{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be68iGaxWJ3V"
      },
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0Y3OiA2vTkZ-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "from typing import List\n",
        "\n",
        "import chromadb\n",
        "from chromadb.api.types import Documents, Embeddings\n",
        "from chromadb.utils.embedding_functions import EmbeddingFunction\n",
        "\n",
        "import google.generativeai as genai\n",
        "\n",
        "import gradio as gr\n",
        "import fitz  # 要安裝PyMuPDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATPAganzwKjS"
      },
      "source": [
        "# Download PDF and Extract text from PDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "dnd8o8dJWwfh"
      },
      "outputs": [],
      "source": [
        "def download_pdf(url, save_path):\n",
        "    \"\"\"\n",
        "    從指定 URL 下載 PDF 文件並儲存到本地。\n",
        "\n",
        "    :param url: PDF 文件的網址 (string)\n",
        "    :param save_path: PDF 文件儲存的本地路徑 (string)\n",
        "    \"\"\"\n",
        "    # 使用 requests 模組發送 HTTP GET 請求以獲取 PDF 文件\n",
        "    response = requests.get(url)\n",
        "\n",
        "    # 打開指定的本地儲存路徑，使用二進位寫入模式 ('wb')\n",
        "    with open(save_path, 'wb') as f:\n",
        "        # 將下載的文件內容寫入到本地文件中\n",
        "        f.write(response.content)\n",
        "\n",
        "\n",
        "def extract_text_from_pdf_file_obj(file):\n",
        "    \"\"\"\n",
        "    從 PDF 檔案物件提取文本內容。\n",
        "\n",
        "    :param file: PDF 文件的檔案物件 (e.g., 通過 open(file, 'rb') 獲取)\n",
        "    :return: 提取的文本內容 (string)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with fitz.open(file.name) as doc:\n",
        "            pdf_text = \"\"\n",
        "            for page in doc:\n",
        "                pdf_text += page.get_text()\n",
        "        return pdf_text\n",
        "    except Exception as e:\n",
        "        return f\"Error while reading PDF: {str(e)}\"\n",
        "\n",
        "\n",
        "def extract_text_from_pdf_file_path(file_path):\n",
        "    \"\"\"\n",
        "    從 PDF 文件的路徑提取文本內容。\n",
        "\n",
        "    :param file_path: PDF 文件的檔案路徑 (string)\n",
        "    :return: 提取的文本內容 (string)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with fitz.open(file_path) as doc:\n",
        "            pdf_text = \"\"\n",
        "            for page in doc:\n",
        "                pdf_text += page.get_text()\n",
        "        return pdf_text\n",
        "    except Exception as e:\n",
        "        return f\"Error while reading PDF: {str(e)}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DF0z6jspWTyF"
      },
      "source": [
        "# ToDo:\n",
        "- Text splitting\n",
        "- ChromaDB\n",
        "- Prompt Construction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5bU0WilGZca"
      },
      "source": [
        "## Implement text splitting function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "GrW4ejl4Fm5u"
      },
      "outputs": [],
      "source": [
        "# 分割文本為小塊\n",
        "def split_text(text: str, max_chunk_size: int = 500, overlap: int = 50) -> List[str]:\n",
        "    \"\"\"\n",
        "    將長文本分割為多個小塊，支援塊之間的重疊。\n",
        "\n",
        "    :param text: 要分割的文本 (string)\n",
        "    :param max_chunk_size: 每個文本塊的最大大小 (int)\n",
        "    :param overlap: 每個文本塊之間的重疊大小 (int)\n",
        "    :return: 分割後的文本塊列表 (List of strings)\n",
        "    \"\"\"\n",
        "    chunks = []\n",
        "    start = 0\n",
        "    while start < len(text):\n",
        "        end = min(start + max_chunk_size, len(text))\n",
        "        chunks.append(text[start:end].strip())\n",
        "        start += max_chunk_size - overlap\n",
        "    return chunks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pxb_4mmFGg-h"
      },
      "source": [
        "## Custom embedding function using Gemini API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "qZqtNV_nFy-M"
      },
      "outputs": [],
      "source": [
        "# 自定義 Gemini 嵌入函數\n",
        "class GeminiEmbeddingFunction(EmbeddingFunction):\n",
        "    def __init__(self, api_key: str, model: str = \"models/embedding-001\", title: str = \"Custom query\"):\n",
        "        self.api_key = api_key\n",
        "        self.model = model\n",
        "        self.title = title\n",
        "        genai.configure(api_key=self.api_key)\n",
        "\n",
        "    def __call__(self, input: Documents) -> Embeddings:\n",
        "        return [\n",
        "            genai.embed_content(\n",
        "                model=self.model,\n",
        "                content=doc,\n",
        "                task_type=\"retrieval_document\",\n",
        "                title=self.title\n",
        "            )[\"embedding\"]\n",
        "            for doc in input\n",
        "        ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qi9IA2FiGmwk"
      },
      "source": [
        "## Implement ChromaDB creation and querying"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "75pEi_qbWwfj"
      },
      "outputs": [],
      "source": [
        "# 向現有的 ChromaDB 集合中新增文件。\n",
        "def update_chroma_db(client, collection_name: str, new_documents: List[str]):\n",
        "    \"\"\"\n",
        "    向現有的 ChromaDB 集合中新增文件。\n",
        "\n",
        "    :param path: ChromaDB 的資料庫路徑 (string)\n",
        "    :param collection_name: 要更新的集合名稱 (string)\n",
        "    :param new_documents: 要新增的文件列表 (List of strings)\n",
        "    \"\"\"\n",
        "\n",
        "    # Get the existing collection by name\n",
        "    collection = client.get_or_create_collection(collection_name)\n",
        "\n",
        "    # Add new documents to the collection\n",
        "    for i, document in enumerate(new_documents):\n",
        "        collection.add(\n",
        "            ids=[f\"new_doc_{i}\"],  # New unique ID for each document\n",
        "            documents=[document],  # New document content\n",
        "        )\n",
        "\n",
        "    print(f\"Added {len(new_documents)} new documents to the collection '{collection_name}'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "bqBRdBb10CB6"
      },
      "outputs": [],
      "source": [
        "# 查詢相關段落\n",
        "def get_relevant_passage(query: str, db, name: str, n_results: int = 3) -> List[str]:\n",
        "    \"\"\"\n",
        "    從指定的 ChromaDB 集合中查詢與給定問題相關的段落。\n",
        "\n",
        "    :param query: 用戶的查詢語句 (string)\n",
        "    :param db: 連接的 ChromaDB 資料庫對象\n",
        "    :param name: 要查詢的集合名稱 (string)\n",
        "    :param n_results: 返回的相關結果數量 (int, 默認為 3)\n",
        "    :ret\n",
        "    \"\"\"\n",
        "    collection = db.get_collection(name)\n",
        "    results = collection.query(query_texts=[query], n_results=n_results)\n",
        "    return results[\"documents\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "c6Mb0RSDGwRf"
      },
      "outputs": [],
      "source": [
        "# 建構提示詞\n",
        "def make_rag_prompt(query: str, relevant_passages: List[str]) -> str:\n",
        "    context = \"\\n\\n\".join(relevant_passages)\n",
        "    return f\"\"\"\n",
        "    You are an intelligent assistant. Use the following context to answer the question:\n",
        "\n",
        "    Context:\n",
        "    {context}\n",
        "\n",
        "    Question:\n",
        "    {query}\n",
        "\n",
        "    Provide a concise and accurate response.\n",
        "    \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSO0EfflwBUa"
      },
      "source": [
        "# LLM Response Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0T1PfvaWwfk",
        "outputId": "66a01aa4-e3a5-40a0-a76f-17f8e30669f5"
      },
      "outputs": [],
      "source": [
        "# Check Gemini API key\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "# 載入 .env 文件中的所有變數\n",
        "load_dotenv(\"key.env\")\n",
        "\n",
        "# 使用 os.getenv 獲取環境變數\n",
        "api_key = os.getenv('Geminiapikey')\n",
        "\n",
        "\n",
        "# 確認變數是否正確載入\n",
        "print(f\"Gemini api key: {api_key}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "toYV28pPv_hj"
      },
      "outputs": [],
      "source": [
        "# Generate answer using Gemini Pro API\n",
        "def generate_answer(prompt: str):\n",
        "    load_dotenv()\n",
        "    api_key = os.getenv('Geminiapikey')\n",
        "    gemini_api_key = api_key\n",
        "    if not gemini_api_key:\n",
        "        raise ValueError(\n",
        "            \"Gemini API Key not provided. Please provide GEMINI_API_KEY as an environment variable\")\n",
        "    genai.configure(api_key=gemini_api_key)\n",
        "    model = genai.GenerativeModel('gemini-pro')\n",
        "    result = model.generate_content(prompt)\n",
        "    return result.text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nDaJf9YWwfl"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fyH03P_Wwfl",
        "outputId": "6f1d9da0-715c-4797-cf9b-db06c5aca7ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rag_experiment is created\n"
          ]
        }
      ],
      "source": [
        "# Set up configurations\n",
        "pdf_url = \"https://services.google.com/fh/files/misc/ai_adoption_framework_whitepaper.pdf\"\n",
        "pdf_path = \"ai_adoption_framework_whitepaper.pdf\"\n",
        "\n",
        "db_folder = \"chroma_db\"\n",
        "db_path = os.path.join(os.getcwd(), db_folder)\n",
        "\n",
        "# Create database directory\n",
        "if not os.path.exists(db_folder):\n",
        "    os.makedirs(db_folder)\n",
        "\n",
        "\n",
        "client = chromadb.PersistentClient(path=db_path)\n",
        "\n",
        "# a database unit in Chroma is called collection, so db here means collection\n",
        "db_name = \"rag_experiment\"\n",
        "client.get_or_create_collection(db_name)\n",
        "print(f\"{db_name} is created\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5xwd91VWwfl",
        "outputId": "4fc5eb44-5ba9-418e-a660-00cd8e9d6b5b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kd/.cache/chroma/onnx_models/all-MiniLM-L6-v2/onnx.tar.gz: 100%|██████████| 79.3M/79.3M [02:34<00:00, 539kiB/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added 129 new documents to the collection 'rag_experiment'.\n"
          ]
        }
      ],
      "source": [
        "# Download and process PDF\n",
        "download_pdf(pdf_url, pdf_path)\n",
        "pdf_text = extract_text_from_pdf_file_path(pdf_path)\n",
        "\n",
        "# Split text into chunks\n",
        "chunked_text = split_text(pdf_text)\n",
        "\n",
        "update_chroma_db(client, db_name, chunked_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "lI6r-xXzWwfl",
        "outputId": "61f55090-60f8-4504-fad5-de8b2ddde2ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Generated Answer: This file discusses an organization's maturity in adopting and using artificial intelligence (AI) technologies, specifically in the areas of automation, tactical maturity, and use cases of AI within different industries.\n"
          ]
        }
      ],
      "source": [
        "# Process user query\n",
        "query = 'what is this file talking about?'\n",
        "relevant_text = get_relevant_passage(query, client, db_name, n_results=3)\n",
        "\n",
        "# Generate and display answer\n",
        "if relevant_text:\n",
        "    final_prompt = make_rag_prompt(query, \"\".join(relevant_text))\n",
        "    answer = generate_answer(final_prompt)\n",
        "    print(\"\\nGenerated Answer:\", answer)\n",
        "else:\n",
        "    print(\"No relevant information found for the given query.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uahs6MZoWwfl"
      },
      "source": [
        "# Combine Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "3COvG9ayWwfl"
      },
      "outputs": [],
      "source": [
        "# 從 PDF 文件提取文本，分割文本為小塊，並更新 ChromaDB 集合。\n",
        "def add_document_to_db(client, db_name, file):\n",
        "    \"\"\"\n",
        "    :param db_path: ChromaDB 資料庫的路徑 (string)\n",
        "    :param db_name: 要更新的 ChromaDB 集合名稱 (string)\n",
        "    :param file: PDF 文件的二進位文件對象 (BinaryIO)\n",
        "    \"\"\"\n",
        "    pdf_text = extract_text_from_pdf_file_obj(file)\n",
        "\n",
        "    # Split text into chunks\n",
        "    chunked_text = split_text(pdf_text)\n",
        "\n",
        "    update_chroma_db(client, db_name, chunked_text)\n",
        "\n",
        "    print(f\"{db_name} is updated\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "qpF17N1HWwfm"
      },
      "outputs": [],
      "source": [
        "# 基於 RAG (Retrieval-Augmented Generation) 流程生成回答。\n",
        "def rag_response(query, client, db_name):\n",
        "    \"\"\"\n",
        "    :param query: 用戶的查詢語句 (string)\n",
        "    :param client: 連接的 ChromaDB 資料庫客戶端\n",
        "    :param db_name: 查詢的集合名稱 (string)\n",
        "    :return: 生成的回答或錯誤信息 (string)\n",
        "    \"\"\"\n",
        "    # Process user query\n",
        "    relevant_text = get_relevant_passage(query, client, db_name, n_results=3)\n",
        "\n",
        "    # Generate and display answer\n",
        "    if relevant_text:\n",
        "        final_prompt = make_rag_prompt(query, \"\".join(relevant_text))\n",
        "        answer = generate_answer(final_prompt)\n",
        "        response = \"\\nGenerated Answer:\"+answer\n",
        "    else:\n",
        "        response = \"No relevant information found for the given query.\"\n",
        "\n",
        "    return response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LyBBDZfwlzl"
      },
      "source": [
        "# Main execution\n",
        "## ToDo:\n",
        " - Chat history\n",
        " - Multiple file injest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JirE2HszWwfm"
      },
      "source": [
        "# Initilaize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "KhQLbvm4Wwfm"
      },
      "outputs": [],
      "source": [
        "# 初始化 ChromaDB 資料庫，創建資料庫目錄並設置集合。\n",
        "def initialize_database(db_folder: str, db_name: str) -> chromadb.PersistentClient:\n",
        "    \"\"\"\n",
        "    :param db_folder: 資料庫文件夾名稱 (string)\n",
        "    :param db_name: 資料庫集合名稱 (string)\n",
        "    :return: 已初始化的 ChromaDB 客戶端 (chromadb.PersistentClient)\n",
        "    \"\"\"\n",
        "    # 獲取當前工作目錄，構建完整的資料庫路徑\n",
        "    db_path = os.path.join(os.getcwd(), db_folder)\n",
        "\n",
        "    # 如果資料庫目錄不存在，則創建該目錄\n",
        "    if not os.path.exists(db_folder):\n",
        "        os.makedirs(db_folder)\n",
        "\n",
        "    # 創建一個 PersistentClient 連接到指定的資料庫路徑\n",
        "    client = chromadb.PersistentClient(path=db_path)\n",
        "\n",
        "    # 在資料庫中創建或獲取指定名稱的集合\n",
        "    client.get_or_create_collection(db_name)\n",
        "\n",
        "    # 打印提示信息，確認集合已創建或存在\n",
        "    print(f\"Collection '{db_name}' is initialized in {db_folder}.\")\n",
        "\n",
        "    # 返回已初始化的客戶端對象\n",
        "    return client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61PrhwWAWwfm",
        "outputId": "0e475c58-8bce-4a32-ee61-e30b11b9b07b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collection 'rag_experiment' is initialized in chroma_db.\n",
            "<chromadb.api.client.Client object at 0x7fcbb2e9feb0>\n"
          ]
        }
      ],
      "source": [
        "db_folder = \"chroma_db\"\n",
        "db_name = \"rag_experiment\"\n",
        "\n",
        "client = initialize_database(db_folder, db_name)\n",
        "print(client)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hge6K8BxWwfm"
      },
      "source": [
        "# gradio UI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnyvCnc5Wwfn",
        "outputId": "9c426c4a-6edd-4c96-f13a-af6a8cba7e4b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kd/.local/lib/python3.10/site-packages/gradio/components/chatbot.py:284: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# 初始化聊天歷史\n",
        "chat_history = []  # 用於存儲用戶和機器人之間的所有對話\n",
        "\n",
        "# 定義用戶輸入的交互邏輯\n",
        "\n",
        "\n",
        "def respond(input_text, history):\n",
        "    \"\"\"\n",
        "    處理用戶輸入，生成回應並更新聊天歷史。\n",
        "    Args:\n",
        "        input_text (str): 用戶的輸入訊息。\n",
        "        history (list): 聊天歷史記錄。\n",
        "    Returns:\n",
        "        tuple: 清空的輸入框和更新後的聊天歷史。\n",
        "    \"\"\"\n",
        "    # 確保聊天歷史初始化為空列表\n",
        "    if history is None:\n",
        "        history = []\n",
        "\n",
        "    # 使用 RAG 模型生成回應\n",
        "    bot_response = rag_response(input_text, client, db_name)\n",
        "\n",
        "    # 將用戶輸入和機器人回應追加到歷史記錄\n",
        "    history.append([input_text, bot_response])  # 每次對話為 [用戶訊息, 機器人回應]\n",
        "\n",
        "    return \"\", history  # 返回清空的輸入框和新的聊天歷史\n",
        "\n",
        "# 處理 PDF 文件上傳的函數\n",
        "\n",
        "\n",
        "def handle_pdf_upload(file):\n",
        "    \"\"\"\n",
        "    處理用戶上傳的 PDF 文件。\n",
        "    Args:\n",
        "        file (File): 上傳的文件對象。\n",
        "    Returns:\n",
        "        str: 文件處理狀態信息。\n",
        "    \"\"\"\n",
        "    if file is None:\n",
        "        return \"尚未上傳文件。\"\n",
        "\n",
        "    # 檢查文件格式是否為 PDF\n",
        "    if not file.name.endswith(\".pdf\"):\n",
        "        return \"僅支持上傳 PDF 文件！\"\n",
        "\n",
        "    # 模擬將文件添加到數據庫\n",
        "    add_document_to_db(client, db_name, file)\n",
        "    return f\"已上傳文件：{file.name}\"\n",
        "\n",
        "\n",
        "# 定義 Gradio 接口\n",
        "with gr.Blocks(css=\"\"\"\n",
        "    @import url('https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css');\n",
        "    .container { max-width: 600px; margin: auto; background: white; padding: 20px; border-radius: 10px; }\n",
        "    .btn-primary { background-color: #007bff; border: none; padding: 10px; }\n",
        "    .btn-danger { background-color: #dc3545; border: none; padding: 10px; }\n",
        "\"\"\") as demo:\n",
        "    with gr.Column(elem_id=\"container\"):\n",
        "        gr.Markdown(\"<h2 class='text-primary text-center'>food recommendation chatbot</h2>\")\n",
        "        chatbot = gr.Chatbot()\n",
        "        user_input = gr.Textbox(placeholder=\"eg. what can I eat as a vegetarian\", label=\"input\")\n",
        "\n",
        "        with gr.Row():\n",
        "            send_btn = gr.Button(\"🍕 submit\", elem_classes=\"btn btn-primary\")\n",
        "            clear_btn = gr.Button(\"🗑 delete\", elem_classes=\"btn btn-danger\")\n",
        "\n",
        "        file_upload = gr.File(label=\"📂 upload PDF\", file_types=[\".pdf\"])\n",
        "        file_status = gr.Textbox(label=\"status of file\", interactive=False)\n",
        "\n",
        "    file_upload.change(handle_pdf_upload, file_upload, file_status)\n",
        "    user_input.submit(respond, [user_input, chatbot], [user_input, chatbot])\n",
        "    send_btn.click(respond, [user_input, chatbot], [user_input, chatbot])\n",
        "    clear_btn.click(lambda: [], None, chatbot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_Hgi9xaWwfn",
        "outputId": "ef4f3f00-8345-4576-906d-733bd1b45b35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing server running on port: 7860\n"
          ]
        }
      ],
      "source": [
        "# 放這邊是因為launch會很難按到最下面的block\n",
        "demo.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "iSBU0bkuWwfn",
        "outputId": "7e62e857-8bc1-4a72-dc98-39dac13ac437"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* Running on local URL:  http://127.0.0.1:7860\n",
            "* Running on public URL: https://5a850bd9b2b8992b9d.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://5a850bd9b2b8992b9d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "demo.launch(share=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
